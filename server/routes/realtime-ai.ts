/**
 * Real-time AI API Routes
 * Integrates AI processing with WebSocket broadcasting
 */

import { Router, Request, Response } from 'express';
import { RealtimeServer } from '../websocket/realtime-server';

const router = Router();

// Mock AI processing function (replace with actual AI integration)
async function processAIQuery(query: string, context?: any): Promise<any> {
  // Simulate AI processing delay
  await new Promise(resolve => setTimeout(resolve, Math.random() * 3000 + 1000));
  
  // Mock different types of responses based on query
  if (query.toLowerCase().includes('error') || query.toLowerCase().includes('fail')) {
    throw new Error('AI processing failed');
  }
  
  if (query.toLowerCase().includes('sql')) {
    return {
      type: 'sql_generation',
      query: `SELECT * FROM users WHERE name ILIKE '%${query}%';`,
      explanation: 'This query searches for users with names containing the search term.',
      confidence: 0.95
    };
  }
  
  if (query.toLowerCase().includes('chart') || query.toLowerCase().includes('graph')) {
    return {
      type: 'chart_generation',
      chartType: 'bar',
      data: [
        { label: 'Jan', value: 100 },
        { label: 'Feb', value: 150 },
        { label: 'Mar', value: 120 }
      ],
      suggestion: 'Consider adding more data points for better insights.'
    };
  }
  
  return {
    type: 'general_response',
    answer: `I understand you're asking about: "${query}". This is a mock response that would normally be generated by an AI model. The response would be contextual and helpful based on your specific query.`,
    suggestions: [
      'Try asking about SQL queries',
      'Ask for chart generation',
      'Request data analysis'
    ]
  };
}

// AI Query endpoint with WebSocket broadcasting
router.post('/query', async (req: Request & { realtimeServer?: RealtimeServer }, res: Response) => {
  try {
    const { query, userId, sheetId, requestId } = req.body;

    if (!query || !userId || !requestId) {
      return res.status(400).json({
        success: false,
        message: 'Query, userId, and requestId are required',
        code: 'INVALID_REQUEST'
      });
    }

    const realtimeServer = req.realtimeServer;

    try {
      // Broadcast AI start event
      if (realtimeServer) {
        realtimeServer.broadcastAIProgress(requestId, userId, {
          status: 'starting',
          message: 'Processing your AI query...'
        });
      }

      // Process AI query
      const result = await processAIQuery(query, { sheetId });

      // Broadcast AI completion
      if (realtimeServer) {
        realtimeServer.broadcastAIComplete(requestId, userId, result);
      }

      res.json({
        success: true,
        data: {
          requestId,
          result,
          processingTime: Date.now()
        }
      });

    } catch (aiError: any) {
      // Broadcast AI error
      if (realtimeServer) {
        realtimeServer.broadcastAIError(requestId, userId, aiError);
      }

      res.status(500).json({
        success: false,
        message: 'AI processing failed',
        error: aiError.message,
        code: 'AI_ERROR'
      });
    }

  } catch (error: any) {
    console.error('Real-time AI query error:', error);
    res.status(500).json({
      success: false,
      message: 'Internal server error',
      error: error.message,
      code: 'INTERNAL_ERROR'
    });
  }
});

// Stream AI processing (for long-running queries)
router.post('/stream', async (req: Request & { realtimeServer?: RealtimeServer }, res: Response) => {
  try {
    const { query, userId, sheetId, requestId } = req.body;

    if (!query || !userId || !requestId) {
      return res.status(400).json({
        success: false,
        message: 'Query, userId, and requestId are required'
      });
    }

    const realtimeServer = req.realtimeServer;

    // Set up SSE headers
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Headers': 'Cache-Control'
    });

    // Send initial event
    res.write(`data: ${JSON.stringify({ type: 'start', requestId })}\n\n`);

    try {
      // Broadcast start via WebSocket
      if (realtimeServer) {
        realtimeServer.broadcastAIProgress(requestId, userId, {
          status: 'streaming',
          message: 'Starting AI stream...'
        });
      }

      // Simulate streaming AI response
      const steps = [
        'Analyzing your query...',
        'Accessing relevant data...',
        'Processing with AI model...',
        'Generating response...',
        'Finalizing results...'
      ];

      for (let i = 0; i < steps.length; i++) {
        const step = steps[i];
        const progress = Math.round(((i + 1) / steps.length) * 100);

        // Send to SSE stream
        res.write(`data: ${JSON.stringify({
          type: 'progress',
          requestId,
          step,
          progress,
          timestamp: new Date().toISOString()
        })}\n\n`);

        // Broadcast via WebSocket
        if (realtimeServer) {
          realtimeServer.broadcastAIProgress(requestId, userId, {
            status: 'processing',
            step,
            progress,
            message: `Step ${i + 1}/${steps.length}: ${step}`
          });
        }

        // Simulate processing time
        await new Promise(resolve => setTimeout(resolve, 1000));
      }

      // Generate final result
      const result = await processAIQuery(query, { sheetId });

      // Send final result
      res.write(`data: ${JSON.stringify({
        type: 'complete',
        requestId,
        result,
        timestamp: new Date().toISOString()
      })}\n\n`);

      // Broadcast completion
      if (realtimeServer) {
        realtimeServer.broadcastAIComplete(requestId, userId, result);
      }

    } catch (error: any) {
      // Send error event
      res.write(`data: ${JSON.stringify({
        type: 'error',
        requestId,
        error: error.message,
        timestamp: new Date().toISOString()
      })}\n\n`);

      // Broadcast error
      if (realtimeServer) {
        realtimeServer.broadcastAIError(requestId, userId, error);
      }
    }

    res.end();

  } catch (error: any) {
    console.error('AI streaming error:', error);
    res.status(500).json({
      success: false,
      message: 'Streaming error',
      error: error.message
    });
  }
});

// Get AI processing status
router.get('/status/:requestId', async (req: Request, res: Response) => {
  try {
    const { requestId } = req.params;

    // In a real implementation, you'd check a database or cache
    // For now, return a mock status
    res.json({
      success: true,
      data: {
        requestId,
        status: 'completed',
        startedAt: new Date(Date.now() - 30000).toISOString(),
        completedAt: new Date().toISOString(),
        processingTime: 30000
      }
    });

  } catch (error: any) {
    console.error('AI status check error:', error);
    res.status(500).json({
      success: false,
      message: 'Status check failed',
      error: error.message
    });
  }
});

// List recent AI requests for a user
router.get('/history/:userId', async (req: Request, res: Response) => {
  try {
    const { userId } = req.params;
    const { limit = 10 } = req.query;

    // Mock history data
    const history = Array.from({ length: parseInt(limit as string) }, (_, i) => ({
      requestId: `ai_${Date.now() - i * 60000}_${Math.random().toString(36).substr(2, 9)}`,
      query: `Sample AI query ${i + 1}`,
      status: i % 4 === 0 ? 'error' : 'completed',
      createdAt: new Date(Date.now() - i * 60000).toISOString(),
      completedAt: i % 4 === 0 ? null : new Date(Date.now() - i * 60000 + 5000).toISOString(),
      result: i % 4 === 0 ? null : {
        type: 'general_response',
        answer: `Mock AI response for query ${i + 1}`
      }
    }));

    res.json({
      success: true,
      data: {
        userId,
        history,
        total: history.length
      }
    });

  } catch (error: any) {
    console.error('AI history error:', error);
    res.status(500).json({
      success: false,
      message: 'History retrieval failed',
      error: error.message
    });
  }
});

export default router;